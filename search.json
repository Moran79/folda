[{"path":"http://iamwangsiyu.com/folda/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 folda authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"why-use-the-folda-package","dir":"Articles","previous_headings":"","what":"Why use the folda package?","title":"Introduction to folda","text":"’ve ever frustrated warnings errors MASS::lda(), appreciate ULDA implementation folda(). offers several key improvements: “constant within group” errors! ULDA can handle constant columns perfect separation groups. Automatic missing value handling! implementation seamlessly integrates automatic missing value imputation training testing phases. Fast! ULDA implemented using Generalized Singular Value Decomposition (GSVD) method, diagonalizes within-class total scatter matrices simultaneously, offering speed advantage sequential diagonalization used MASS::lda() (see Howland et al., 2003 details). also rewritten matrix decomposition modules (SVD, QR) using RcppEigen, improving computational efficiency leveraging optimized C++ code. Better visualization! folda uses ggplot2 provide visualizations class separation projected 2D spaces (1D histograms), offering valuable insights. forward LDA implementation, folda offers following advantages classical framework: issues multicollinearity perfect linear dependency! Since folda() built ULDA, effectively solves scaling matrix. Handles perfect separation offers greater power! classical approach using Wilks’ Lambda known limitations, including premature stopping () groups perfectly separated. Pillai’s trace, used folda(), effectively addresses perfect separation, also shown generally greater statistical power Wilks’ Lambda (Rencher et al., 2002).","code":""},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"basic-usage-of-folda","dir":"Articles","previous_headings":"","what":"Basic Usage of folda","title":"Introduction to folda","text":"Build ULDA model variables: Build ULDA model forward selection via Pillai’s trace: Plot results:  Make predictions:","code":"library(folda) mpg <- as.data.frame(ggplot2::mpg) # Prepare the data datX <- mpg[, -5] # All predictors without Y response <- mpg[, 5] # we try to predict \"cyl\" (number of cylinders) fit <- folda(datX = datX, response = response, subsetMethod = \"all\") fit <- folda(datX = datX, response = response, subsetMethod = \"forward\", testStat = \"Pillai\") print(fit) # 6 out of 11 variables are selected, displ is the most important among them #>  #> Overall Pillai's trace: 1.325 #> Associated p-value: 4.636e-74 #>  #> Prediction Results on Training Data: #> Refitting Accuracy: 0.9188 #> Gini Index: 0.7004 #>  #> Confusion Matrix: #>          Actual #> Predicted  4  5  6  8 #>         4 69  0  3  0 #>         5  8  4  2  0 #>         6  4  0 74  2 #>         8  0  0  0 68 #>  #> Group means of LD scores: #>           LD1         LD2        LD3 #> 4 -3.05298379 -0.02700248 -0.3555829 #> 5 -1.87744449  4.45014946  0.8156167 #> 6 -0.06757888 -0.28356907  0.5911862 #> 8  3.71628852  0.09697943 -0.3023424 #>  #> Forward Selection Results: #>                var statOverall   statDiff  threshold #> 1            displ    0.873393 0.87339300 0.06545381 #> 2  modelnew beetle    1.029931 0.15653777 0.05673510 #> 3       modeljetta    1.141651 0.11172064 0.05496185 #> 4 modelcaravan 2wd    1.210165 0.06851331 0.05363507 #> 5     classmidsize    1.263449 0.05328468 0.05276500 #> 6              cty    1.325255 0.06180560 0.05194279 plot(fit, datX = datX, response = response) head(predict(fit, datX, type = \"response\")) #> [1] \"4\" \"4\" \"4\" \"4\" \"6\" \"4\" head(predict(fit, datX, type = \"prob\")) # Posterior probabilities #>           4            5            6            8 #> 1 0.9966769 7.475058e-08 0.0033230408 7.023764e-12 #> 2 0.9994438 1.401133e-08 0.0005562131 5.338710e-13 #> 3 0.9970911 3.835722e-08 0.0029088506 1.738154e-11 #> 4 0.9983963 2.196016e-08 0.0016037009 7.365641e-12 #> 5 0.3122116 6.809673e-07 0.6877815595 6.173116e-06 #> 6 0.5995781 4.275271e-07 0.4004193019 2.123291e-06"},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"comparison-of-pillais-trace-and-wilks-lambda","dir":"Articles","previous_headings":"","what":"Comparison of Pillai’s Trace and Wilks’ Lambda","title":"Introduction to folda","text":", compare performances scenario one group classes perfectly separable another, condition Wilks’ Lambda performs poorly. Now let’s predict model car. Wilks’ Lambda selects manufacturer-audi, since can separate a4, a4 quattro, a6 quattro models. However, unexpectedly stops since Wilks’ Lambda = 0, leading refitting accuracy 0.0812. hand, Pillai’s trace selects 26 variables total refitting accuracy 0.9231. Additionally, MASS::lda() throw error scenario due “constant within groups” issue.","code":"fitW <- folda(mpg[, -2], mpg[, 2], testStat = \"Wilks\") fitW$forwardInfo #>                var statOverall statDiff threshold #> 1 manufactureraudi           0        0 0.7338759 fitP <- folda(mpg[, -2], mpg[, 2], testStat = \"Pillai\") fitP$forwardInfo #>                       var statOverall  statDiff threshold #> 1       manufacturerdodge     1.00000 1.0000000 0.2654136 #> 2  manufacturervolkswagen     2.00000 1.0000000 0.2599086 #> 3        manufactureraudi     3.00000 1.0000000 0.2543730 #> 4        manufacturerford     4.00000 1.0000000 0.2488055 #> 5   manufacturerchevrolet     5.00000 1.0000000 0.2432051 #> 6       manufacturerhonda     6.00000 1.0000000 0.2375706 #> 7     manufacturerhyundai     7.00000 1.0000000 0.2319008 #> 8        manufacturerjeep     8.00000 1.0000000 0.2261943 #> 9  manufacturerland rover     9.00000 1.0000000 0.2204496 #> 10    manufacturerlincoln    10.00000 1.0000000 0.2146652 #> 11    manufacturermercury    11.00000 1.0000000 0.2088394 #> 12     manufacturernissan    12.00000 1.0000000 0.2029702 #> 13    manufacturerpontiac    13.00000 1.0000000 0.1970556 #> 14     manufacturersubaru    14.00000 1.0000000 0.1910933 #> 15                   drvf    15.00000 1.0000000 0.1850810 #> 16                   drvr    16.00000 1.0000000 0.1785056 #> 17           classminivan    17.00000 1.0000000 0.1723677 #> 18            classpickup    18.00000 1.0000000 0.1661696 #> 19               classsuv    19.00000 1.0000000 0.1599071 #> 20           classmidsize    19.93159 0.9315947 0.1535761 #> 21        classsubcompact    20.74392 0.8123229 0.1475693 #> 22           classcompact    21.71027 0.9663480 0.1421899 #> 23                  displ    21.96954 0.2592742 0.1358348 #> 24          transauto(s5)    22.16831 0.1987676 0.1335988 #> 25                    cty    22.35530 0.1869879 0.1316772 #> 26                    flp    22.52155 0.1662562 0.1297761 # MASS::lda(model~., data = mpg)  #> Error in lda.default(x, grouping, ...) :  #>   variables  1  2  3  4  5  6  7  8  9 10 11 12 13 14 27 28 37 38 40 appear to be constant within groups"},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"handling-missing-values","dir":"Articles","previous_headings":"","what":"Handling Missing Values","title":"Introduction to folda","text":"default method handle missing values c(medianFlag, newLevel). means numerical variables, missing values imputed median, categorical variables, new level assigned represent missing values. Additionally, numerical variables, generate missing value indicators flag observations missing data. Two key functions involved process missingFix() getDataInShape(): missingFix() imputes missing values outputs two objects: imputed dataset missing reference, can used future imputations. constant columns remains imputed dataset removed. getDataInShape() takes new data missing reference inputs, returns imputed dataset. function performs several tasks: Redundant column removal: columns new data present reference removed. Missing column addition: Columns present reference missing new data added initialized according missing reference. Flag variable handling: Missing value indicators (flag variables) properly updated reflect missing values new data. Factor level updating: categorical variables, factor levels updated match reference. factor variable new data contains levels present reference, levels removed, values set match reference. Redundant levels also removed. Impute missing values create missing reference: X1 X2 removed constant (.e., values NA). X3 X4 remain unchanged. X5 imputed median (3), new column X5_FLAG added indicate missing values. X6 imputed new level ‘new0_0Level’. Now, let’s create new dataset imputation. Apply missing reference new dataset: X1 removed exist missing reference. X3 remains unchanged. “F” new level X4, removed imputed “” (frequent level) along missing values. X5 imputed, new column X5_FLAG added indicate missing values. X6 missing new data, initialized level “new0_0Level”. Next, show example using folda airquality dataset. First, let’s check columns airquality missing values: response variable 5th column (Month): generated missing reference : make prediction: Notice issues arise predicting, even new data contains nothing missing values.","code":"# Create a dataset with missing values (datNA <- data.frame(X1 = rep(NA, 5), # All values are NA                      X2 = factor(rep(NA, 5), levels = LETTERS[1:3]), # Factor with all NA values                      X3 = 1:5, # Numeric column with no missing values                      X4 = LETTERS[1:5], # Character column                      X5 = c(NA, 2, 3, 10, NA), # Numeric column with missing values                      X6 = factor(c(\"A\", NA, NA, \"B\", \"B\"), levels = LETTERS[1:3]))) # Factor with missing values #>   X1   X2 X3 X4 X5   X6 #> 1 NA <NA>  1  A NA    A #> 2 NA <NA>  2  B  2 <NA> #> 3 NA <NA>  3  C  3 <NA> #> 4 NA <NA>  4  D 10    B #> 5 NA <NA>  5  E NA    B (imputedSummary <- missingFix(datNA)) #> $data #>   X3 X4 X5          X6 X5_FLAG #> 1  1  A  3           A       1 #> 2  2  B  2 new0_0Level       0 #> 3  3  C  3 new0_0Level       0 #> 4  4  D 10           B       0 #> 5  5  E  3           B       1 #>  #> $ref #>   X3 X4 X5          X6 X5_FLAG #> 1  3  A  3 new0_0Level       1 (datNAnew <- data.frame(X1 = 1:3, # New column not in the reference                         X3 = 1:3, # Matching column with no NAs                         X4 = as.factor(c(\"E\", \"F\", NA)), # Factor with a new level \"F\" and missing values                         X5 = c(NA, 2, 3))) # Numeric column with a missing value #>   X1 X3   X4 X5 #> 1  1  1    E NA #> 2  2  2    F  2 #> 3  3  3 <NA>  3 getDataInShape(datNAnew, imputedSummary$ref) #>   X3 X4 X5          X6 X5_FLAG #> 1  1  E  3 new0_0Level       1 #> 2  2  A  2 new0_0Level       0 #> 3  3  A  3 new0_0Level       0 sapply(airquality, anyNA) # Ozone and Solar.R have NAs #>   Ozone Solar.R    Wind    Temp   Month     Day  #>    TRUE    TRUE   FALSE   FALSE   FALSE   FALSE fitAir <- folda(airquality[, -5], airquality[, 5]) fitAir$misReference #>   Ozone Solar.R Wind Temp Day Ozone_FLAG Solar.R_FLAG #> 1  31.5     205  9.7   79  16          1            1 predict(fitAir, data.frame(rep(NA, 4))) #> [1] \"6\" \"6\" \"6\" \"6\""},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"additional-features","dir":"Articles","previous_headings":"","what":"Additional Features","title":"Introduction to folda","text":"correction: ’re less concerned controlling type error prefer aggressive variable selection process, setting correction = FALSE may result better testing accuracy, particularly number columns exceeds number rows. alpha: goal rank variables, set alpha = 1. ensures variables filtered selection process. misClassCost: parameter useful situations misclassifying certain classes severe impact compared others. example demonstrating incorporate different misclassification costs. iris dataset famous dataset three species flowers: Suppose misclassifying versicolor species costly. potential misclassification cost matrix might look like : means misclassifying versicolor species 100 times severe misclassifying species versicolor. First, let’s fit model equal misclassification costs specified misclassification costs: prediction distributions equal misclassification costs: prediction distributions specified misclassification costs: shown, model tends predict versicolor often due higher misclassification cost associated predicting incorrectly.","code":"table(iris$Species, dnn = NULL) #>     setosa versicolor  virginica  #>         50         50         50 misClassCost <- matrix(c(0, 100, 1,                          1, 0, 1,                          1, 100, 0), 3, 3, byrow = TRUE) fitEqualCost <- folda(iris[, -5], response = iris[, 5]) fitNewCost <- folda(iris[, -5], response = iris[, 5], misClassCost = misClassCost) table(predict(fitEqualCost, iris), dnn = NULL) #>     setosa versicolor  virginica  #>         50         49         51 table(predict(fitNewCost, iris), dnn = NULL) #>     setosa versicolor  virginica  #>         50         63         37"},{"path":"http://iamwangsiyu.com/folda/articles/folda.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Introduction to folda","text":"Howland, P., Jeon, M., & Park, H. (2003). Structure preserving dimension reduction clustered text data based generalized singular value decomposition. SIAM Journal Matrix Analysis Applications, 25(1), 165-179. Rencher, . C., & Christensen, W. F. (2002). Methods multivariate analysis (Vol. 727). John Wiley & Sons.","code":""},{"path":"http://iamwangsiyu.com/folda/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Siyu Wang. Author, maintainer, copyright holder.","code":""},{"path":"http://iamwangsiyu.com/folda/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wang S (2024). folda: Forward Stepwise Discriminant Analysis Pillai's Trace. R package version 0.0.9, http://iamwangsiyu.com/folda/, https://github.com/Moran79/folda.","code":"@Manual{,   title = {folda: Forward Stepwise Discriminant Analysis with Pillai's Trace},   author = {Siyu Wang},   year = {2024},   note = {R package version 0.0.9, http://iamwangsiyu.com/folda/},   url = {https://github.com/Moran79/folda}, }"},{"path":"http://iamwangsiyu.com/folda/index.html","id":"folda-","dir":"","previous_headings":"","what":"Forward Stepwise Discriminant Analysis with Pillai's Trace","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"folda package R modeling tool designed fitting Forward Stepwise Linear Discriminant Analysis (LDA) Uncorrelated Linear Discriminant Analysis (ULDA). ’re unfamiliar stepwise LDA ULDA, please refer following resources: stepwise LDA using Wilks’ Lambda, see Section 6.11.1 Methods Multivariate Analysis, Third Edition Alvin C. Rencher William F. Christensen (2012). ULDA, refer Ye, J., & Yu, B. (2005). Characterization family algorithms generalized discriminant analysis undersampled problems. Journal Machine Learning Research, 6(4). Link. combination ULDA forward LDA using Pillai’s trace, see Wang, S. (2024). New Forward Discriminant Analysis Framework Based Pillai’s Trace ULDA. arXiv preprint arXiv:2409.03136. Link.","code":""},{"path":"http://iamwangsiyu.com/folda/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"can install development version folda GitHub :","code":"install.packages(\"LDATree\") # install.packages(\"devtools\") devtools::install_github(\"Moran79/folda\")"},{"path":"http://iamwangsiyu.com/folda/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"’ve ever frustrated warnings errors MASS::lda(), appreciate ULDA implementation folda(). offers several key improvements: “constant within group” errors! ULDA can handle constant columns perfect separation groups. Automatic missing value handling! implementation seamlessly integrates automatic missing value imputation training testing phases. Fast! ULDA implemented using Generalized Singular Value Decomposition (GSVD) method, diagonalizes within-class total scatter matrices simultaneously, offering speed advantage sequential diagonalization used MASS::lda() (see Howland et al., 2003 details). also rewritten matrix decomposition modules (SVD, QR) using RcppEigen, improving computational efficiency leveraging optimized C++ code. Better visualization! folda uses ggplot2 provide visualizations class separation projected 2D spaces (1D histograms), offering valuable insights. forward LDA implementation, folda offers following advantages classical framework: issues multicollinearity perfect linear dependency! Since folda() built ULDA, effectively solves scaling matrix. Handles perfect separation offers greater power! classical approach using Wilks’ Lambda known limitations, including premature stopping () groups perfectly separated. Pillai’s trace, used folda(), effectively addresses perfect separation, also shown generally greater statistical power Wilks’ Lambda (Rencher et al., 2002).","code":""},{"path":"http://iamwangsiyu.com/folda/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic Usage","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"Build ULDA model variables: Build ULDA model forward selection via Pillai’s trace: Plot results:  Make predictions: examples can found vignette.","code":"library(folda) mpg <- as.data.frame(ggplot2::mpg) # Prepare the data datX <- mpg[, -5] # All predictors without Y response <- mpg[, 5] # we try to predict \"cyl\" (number of cylinders) fit <- folda(datX = datX, response = response, subsetMethod = \"all\") fit <- folda(datX = datX, response = response, subsetMethod = \"forward\", testStat = \"Pillai\") print(fit) # 6 out of 11 variables are selected, displ is the most important among them #>  #> Overall Pillai's trace: 1.325 #> Associated p-value: 4.636e-74 #>  #> Prediction Results on Training Data: #> Refitting Accuracy: 0.9188 #> Gini Index: 0.7004 #>  #> Confusion Matrix: #>          Actual #> Predicted  4  5  6  8 #>         4 69  0  3  0 #>         5  8  4  2  0 #>         6  4  0 74  2 #>         8  0  0  0 68 #>  #> Group means of LD scores: #>           LD1         LD2        LD3 #> 4  3.05298379  0.02700248 -0.3555829 #> 5  1.87744449 -4.45014946  0.8156167 #> 6  0.06757888  0.28356907  0.5911862 #> 8 -3.71628852 -0.09697943 -0.3023424 #>  #> Forward Selection Results: #>                var statOverall   statDiff  threshold #> 1            displ    0.873393 0.87339300 0.06545381 #> 2  modelnew beetle    1.029931 0.15653777 0.05673510 #> 3       modeljetta    1.141651 0.11172064 0.05496185 #> 4 modelcaravan 2wd    1.210165 0.06851331 0.05363507 #> 5     classmidsize    1.263449 0.05328468 0.05276500 #> 6              cty    1.325255 0.06180560 0.05194279 plot(fit, datX = datX, response = response) head(predict(fit, datX, type = \"response\")) #> [1] \"4\" \"4\" \"4\" \"4\" \"6\" \"4\" head(predict(fit, datX, type = \"prob\")) # Posterior probabilities #>           4            5            6            8 #> 1 0.9966769 7.475058e-08 0.0033230408 7.023764e-12 #> 2 0.9994438 1.401133e-08 0.0005562131 5.338710e-13 #> 3 0.9970911 3.835722e-08 0.0029088506 1.738154e-11 #> 4 0.9983963 2.196016e-08 0.0016037009 7.365641e-12 #> 5 0.3122116 6.809673e-07 0.6877815595 6.173116e-06 #> 6 0.5995781 4.275271e-07 0.4004193019 2.123291e-06"},{"path":"http://iamwangsiyu.com/folda/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"Howland, P., Jeon, M., & Park, H. (2003). Structure preserving dimension reduction clustered text data based generalized singular value decomposition. SIAM Journal Matrix Analysis Applications, 25(1), 165-179. Rencher, . C., & Christensen, W. F. (2002). Methods multivariate analysis (Vol. 727). John Wiley & Sons.","code":""},{"path":"http://iamwangsiyu.com/folda/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Forward Stepwise Discriminant Analysis with Pillai's Trace","text":"encounter clear bug, please file issue minimal reproducible example GitHub","code":""},{"path":"http://iamwangsiyu.com/folda/reference/checkPriorAndMisClassCost.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and Normalize Prior Probabilities and Misclassification Costs — checkPriorAndMisClassCost","title":"Check and Normalize Prior Probabilities and Misclassification Costs — checkPriorAndMisClassCost","text":"function verifies normalizes provided prior probabilities misclassification cost matrix given response variable. ensures lengths prior dimensions misclassification cost matrix match number levels response variable. prior misClassCost provided, default values used: prior set observed frequencies response, misclassification cost matrix set 1 misclassifications 0 correct classifications.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/checkPriorAndMisClassCost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and Normalize Prior Probabilities and Misclassification Costs — checkPriorAndMisClassCost","text":"","code":"checkPriorAndMisClassCost(prior, misClassCost, response)"},{"path":"http://iamwangsiyu.com/folda/reference/checkPriorAndMisClassCost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and Normalize Prior Probabilities and Misclassification Costs — checkPriorAndMisClassCost","text":"prior numeric vector representing prior probabilities class response variable. NULL, observed frequencies response used default prior. misClassCost square matrix representing misclassification costs pair classes response variable. NULL, default misclassification matrix created misclassifications cost 1 correct classifications cost 0. response factor representing response variable multiple classes.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/checkPriorAndMisClassCost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check and Normalize Prior Probabilities and Misclassification Costs — checkPriorAndMisClassCost","text":"list containing: prior normalized vector prior probabilities class. misClassCost square matrix representing misclassification costs, rows columns labeled levels response variable.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward Uncorrelated Linear Discriminant Analysis — folda","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"function fits ULDA (Uncorrelated Linear Discriminant Analysis) model provided data, option forward selection variables based Pillai's trace Wilks' Lambda. can also handle missing values, perform downsampling, compute linear discriminant scores group means classification. function returns fitted ULDA model object.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"","code":"folda(   datX,   response,   subsetMethod = c(\"forward\", \"all\"),   testStat = c(\"Pillai\", \"Wilks\"),   correction = TRUE,   alpha = 0.1,   prior = NULL,   misClassCost = NULL,   missingMethod = c(\"medianFlag\", \"newLevel\"),   downSampling = FALSE,   kSample = NULL )"},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"datX data frame containing predictor variables. response factor representing response variable multiple classes. subsetMethod character string specifying method variable selection. Options \"forward\" forward selection \"\" using variables. Default \"forward\". testStat character string specifying test statistic use forward selection. Options \"Pillai\" \"Wilks\". Default \"Pillai\". correction logical value indicating whether apply multiple comparison correction forward selection. Default TRUE. alpha numeric value 0 1 specifying significance level test statistic forward selection. Default 0.1. prior numeric vector representing prior probabilities class response variable. NULL, observed class frequencies used prior. Default NULL. misClassCost square matrix \\(C\\), element \\(C_{ij}\\) represents cost classifying observation class \\(\\) given truly belongs class \\(j\\). NULL, default matrix equal misclassification costs class pairs used. Default NULL. missingMethod character vector length 2 specifying handle missing values numerical categorical variables, respectively. Default c(\"medianFlag\", \"newLevel\"). downSampling logical value indicating whether perform downsampling balance class distribution training data speed program. Default FALSE. kSample integer specifying maximum number samples take class downsampling. NULL, number samples limited size smallest class. Default NULL.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"list class ULDA containing following components: scaling matrix scaling coefficients linear discriminants. groupMeans group means linear discriminant scores. prior prior probabilities class. misClassCost misclassification cost matrix. misReference reference handling missing values. terms terms used model formula. xlevels levels factors used model. varIdx indices selected variables. varSD standard deviations selected variables. varCenter means selected variables. statPillai Pillai's trace statistic. pValue p-value associated Pillai's trace. predGini Gini index predictions training data. confusionMatrix confusion matrix training data predictions. forwardInfo Information forward selection process, applicable. stopInfo message indicating forward selection stopped, applicable.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"Howland, P., Jeon, M., & Park, H. (2003). Structure preserving dimension reduction clustered text data based generalized singular value decomposition. SIAM Journal Matrix Analysis Applications Wang, S. (2024). New Forward Discriminant Analysis Framework Based Pillai's Trace ULDA. arXiv preprint arXiv:2409.03136. Available https://arxiv.org/abs/2409.03136.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/folda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward Uncorrelated Linear Discriminant Analysis — folda","text":"","code":"# Fit the ULDA model fit <- folda(datX = iris[, -5], response = iris[, 5], subsetMethod = \"all\")  # Fit the ULDA model with forward selection fit <- folda(datX = iris[, -5], response = iris[, 5], subsetMethod = \"forward\")"},{"path":"http://iamwangsiyu.com/folda/reference/forwardSel.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward Selection via Multivariate Test Statistics — forwardSel","title":"Forward Selection via Multivariate Test Statistics — forwardSel","text":"function performs forward selection dataset based multivariate test statistics (Pillai Wilks). iteratively adds variables contribute test statistic significant variables found stopping criterion met.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/forwardSel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward Selection via Multivariate Test Statistics — forwardSel","text":"","code":"forwardSel(m, response, testStat = \"Pillai\", alpha = 0.1, correction = TRUE)"},{"path":"http://iamwangsiyu.com/folda/reference/forwardSel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward Selection via Multivariate Test Statistics — forwardSel","text":"m numeric matrix containing predictor variables. Rows represent observations columns represent variables. response factor representing response variable multiple levels (groups). testStat character string specifying test statistic use. Can \"Pillai\" (default) \"Wilks\". alpha numeric value 0 1 specifying significance level test. Default 0.1. correction logical value indicating whether apply multiple comparison correction. Default TRUE.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/forwardSel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward Selection via Multivariate Test Statistics — forwardSel","text":"list three components: currentVarList vector selected variable indices based forward selection process. forwardInfo data frame containing detailed information forward selection process, including selected variables, test statistics, thresholds. stopInfo character string describing selection process stopped.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/forwardSel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forward Selection via Multivariate Test Statistics — forwardSel","text":"Wang, S. (2024). New Forward Discriminant Analysis Framework Based Pillai's Trace ULDA. arXiv preprint arXiv:2409.03136. Available https://arxiv.org/abs/2409.03136.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getBestVar.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Best Variable at Current Step Based on Multivariate Test Statistics — getBestVar","title":"Select Best Variable at Current Step Based on Multivariate Test Statistics — getBestVar","text":"function selects best variable based specified multivariate test statistic (Pillai Wilks). evaluates statistic candidate variable newVar combined currentVar, returns index test statistic best variable. also identifies collinear variables.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getBestVar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Best Variable at Current Step Based on Multivariate Test Statistics — getBestVar","text":"","code":"getBestVar(currentVar, newVar, Sw, St, testStat = \"Pillai\")"},{"path":"http://iamwangsiyu.com/folda/reference/getBestVar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Best Variable at Current Step Based on Multivariate Test Statistics — getBestVar","text":"currentVar numeric vector indicating indices currently selected variables. newVar numeric vector indicating indices candidate variables tested. Sw matrix representing within-class scatter matrix. St matrix representing total scatter matrix. testStat character string specifying test statistic use. Can either \"Pillai\" \"Wilks\". Default \"Pillai\".","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getBestVar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Best Variable at Current Step Based on Multivariate Test Statistics — getBestVar","text":"list containing: stopflag logical value indicating whether best variable collinear (.e., selection stop). varIdx index selected variable newVar based test statistic. stat value test statistic selected variable. collinearVar vector indices newVar representing collinear variables.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDataInShape.html","id":null,"dir":"Reference","previous_headings":"","what":"Align Data with a Missing Reference — getDataInShape","title":"Align Data with a Missing Reference — getDataInShape","text":"function aligns given dataset (data) reference dataset (missingReference). ensures structure, column names, factor levels data match structure missingReference. necessary, missing columns initialized NA, factor levels adjusted match reference. Additionally, handles imputation missing values based reference manages flag variables categorical numerical columns.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDataInShape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Align Data with a Missing Reference — getDataInShape","text":"","code":"getDataInShape(data, missingReference)"},{"path":"http://iamwangsiyu.com/folda/reference/getDataInShape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Align Data with a Missing Reference — getDataInShape","text":"data data frame aligned adjusted according missingReference. missingReference reference data frame provides structure (column names, factor levels, missing value reference) aligning data.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDataInShape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Align Data with a Missing Reference — getDataInShape","text":"data frame structure, column names, factor levels data aligned missingReference. Missing values data imputed based first row missingReference, flag variables updated accordingly.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDataInShape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Align Data with a Missing Reference — getDataInShape","text":"","code":"data <- data.frame(   X1_FLAG = c(0, 0, 0),   X1 = factor(c(NA, \"C\", \"B\"), levels = LETTERS[2:3]),   X2_FLAG = c(NA, 0, 1),   X2 = c(2, NA, 3) )  missingReference <- data.frame(   X1_FLAG = 1,   X1 = factor(\"A\", levels = LETTERS[1:2]),   X2 = 1,   X2_FLAG = 1 )  getDataInShape(data, missingReference) #>   X1_FLAG X1 X2 X2_FLAG #> 1       1  A  2       0 #> 2       1  A  1       1 #> 3       0  B  3       1"},{"path":"http://iamwangsiyu.com/folda/reference/getDesignMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate the Design Matrix for LDA Model — getDesignMatrix","title":"Generate the Design Matrix for LDA Model — getDesignMatrix","text":"Generate Design Matrix LDA Model","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDesignMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate the Design Matrix for LDA Model — getDesignMatrix","text":"","code":"getDesignMatrix(modelLDA, data, scale = FALSE)"},{"path":"http://iamwangsiyu.com/folda/reference/getDesignMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate the Design Matrix for LDA Model — getDesignMatrix","text":"modelLDA fitted LDA model object containing terms, variable indices, variable centers, scaling factors. data data frame containing predictor variables used create design matrix. scale logical value indicating whether scale design matrix based mean standard deviation variables (default FALSE).","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDesignMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate the Design Matrix for LDA Model — getDesignMatrix","text":"design matrix row corresponds observation column predictor variable. scale = TRUE, variables centered scaled based means standard deviations provided LDA model object.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDownSampleInd.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Function to Generate Training Set Indices Through Downsampling — getDownSampleInd","title":"Helper Function to Generate Training Set Indices Through Downsampling — getDownSampleInd","text":"function selects indices training set based class vector response. allows optional downsampling balance class distribution limiting number samples per class.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDownSampleInd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Function to Generate Training Set Indices Through Downsampling — getDownSampleInd","text":"","code":"getDownSampleInd(response, downSampling = FALSE, kSample = NULL)"},{"path":"http://iamwangsiyu.com/folda/reference/getDownSampleInd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Function to Generate Training Set Indices Through Downsampling — getDownSampleInd","text":"response factor vector representing class labels. downSampling logical value indicating whether downsampling applied. TRUE, downsampling performed limit number samples per class based kSample. Note may result equal class frequencies, kSample defines upper limit class, lower limit. kSample integer specifying maximum number samples selected per class. NULL, number samples limited size smallest class.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getDownSampleInd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Function to Generate Training Set Indices Through Downsampling — getDownSampleInd","text":"integer vector indices representing selected samples original response vector.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getLDscores.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Linear Discriminant Scores — getLDscores","title":"Compute Linear Discriminant Scores — getLDscores","text":"Compute Linear Discriminant Scores","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getLDscores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Linear Discriminant Scores — getLDscores","text":"","code":"getLDscores(modelLDA, data, nScores = -1)"},{"path":"http://iamwangsiyu.com/folda/reference/getLDscores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Linear Discriminant Scores — getLDscores","text":"modelLDA fitted LDA model object containing scaling matrix reference structure missing data. data data frame containing predictor variables compute linear discriminant scores. nScores integer specifying number discriminant scores compute. -1 (default), scores computed.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getLDscores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Linear Discriminant Scores — getLDscores","text":"matrix linear discriminant scores, rows correspond observations columns correspond computed discriminant scores. nScores > 0, specified number scores returned; otherwise, scores computed returned.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getMode.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Mode of a Factor Variable with Optional Priors — getMode","title":"Calculate the Mode of a Factor Variable with Optional Priors — getMode","text":"Calculate Mode Factor Variable Optional Priors","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getMode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Mode of a Factor Variable with Optional Priors — getMode","text":"","code":"getMode(v, prior)"},{"path":"http://iamwangsiyu.com/folda/reference/getMode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Mode of a Factor Variable with Optional Priors — getMode","text":"v factor vector can coerced factor. mode calculated levels factor. prior numeric vector prior weights level factor.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getMode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Mode of a Factor Variable with Optional Priors — getMode","text":"mode factor v character string. values NA, function returns NA.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getNumFlag.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Numeric, Integer, or Logical Columns in a Data Frame — getNumFlag","title":"Identify Numeric, Integer, or Logical Columns in a Data Frame — getNumFlag","text":"function checks whether columns data frame (vector) type numeric, integer, logical. can return logical vector indicating whether column matches types, , index = TRUE, returns indices matching columns.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getNumFlag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Numeric, Integer, or Logical Columns in a Data Frame — getNumFlag","text":"","code":"getNumFlag(data, index = FALSE)"},{"path":"http://iamwangsiyu.com/folda/reference/getNumFlag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Numeric, Integer, or Logical Columns in a Data Frame — getNumFlag","text":"data data frame vector. function check data types columns (data data frame) type vector. index logical value. FALSE (default), function returns logical vector indicating columns numeric, integer, logical. TRUE, returns indices columns.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/getNumFlag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Numeric, Integer, or Logical Columns in a Data Frame — getNumFlag","text":"index = FALSE (default), function returns logical vector one element column (vector ), TRUE indicates column type numeric, integer, logical, FALSE indicates . index = TRUE, function returns integer vector containing indices columns numeric, integer, logical.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/missingFix.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","title":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","text":"function imputes missing values data frame based specified methods numerical categorical variables. Additionally, can add flag columns indicate missing values. numerical variables, missing values can imputed using mean median. categorical variables, missing values can imputed using mode new level. function also removes constant columns (NAs observed value).","code":""},{"path":"http://iamwangsiyu.com/folda/reference/missingFix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","text":"","code":"missingFix(data, missingMethod = c(\"medianFlag\", \"newLevel\"))"},{"path":"http://iamwangsiyu.com/folda/reference/missingFix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","text":"data data frame containing data processed. Missing values (NA) imputed based methods provided missingMethod. missingMethod character vector length 2 specifying methods imputing missing values. first element specifies method numerical variables (\"mean\", \"median\", \"meanFlag\", \"medianFlag\"), second element specifies method categorical variables (\"mode\", \"modeFlag\", \"newLevel\"). \"Flag\" included, flag column added corresponding variable type.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/missingFix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","text":"list two elements: data original data frame missing values imputed, flag columns added applicable. ref reference row containing imputed values flag levels, can used future predictions reference.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/missingFix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute Missing Values and Add Missing Flags to a Data Frame — missingFix","text":"","code":"dat <- data.frame(   X1 = rep(NA, 5),   X2 = factor(rep(NA, 5), levels = LETTERS[1:3]),   X3 = 1:5,   X4 = LETTERS[1:5],   X5 = c(NA, 2, 3, 10, NA),   X6 = factor(c(\"A\", NA, NA, \"B\", \"B\"), levels = LETTERS[1:3]) ) missingFix(dat) #> $data #>   X3 X4 X5          X6 X5_FLAG #> 1  1  A  3           A       1 #> 2  2  B  2 new0_0Level       0 #> 3  3  C  3 new0_0Level       0 #> 4  4  D 10           B       0 #> 5  5  E  3           B       1 #>  #> $ref #>   X3 X4 X5          X6 X5_FLAG #> 1  3  A  3 new0_0Level       1 #>"},{"path":"http://iamwangsiyu.com/folda/reference/nonConstInd.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Non-Constant Columns in a Data Frame — nonConstInd","title":"Identify Non-Constant Columns in a Data Frame — nonConstInd","text":"Identify Non-Constant Columns Data Frame","code":""},{"path":"http://iamwangsiyu.com/folda/reference/nonConstInd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Non-Constant Columns in a Data Frame — nonConstInd","text":"","code":"nonConstInd(data, tol = 1e-08, na.rm = FALSE)"},{"path":"http://iamwangsiyu.com/folda/reference/nonConstInd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Non-Constant Columns in a Data Frame — nonConstInd","text":"data data frame columns checked constant values. Columns can type (numeric, integer, logical, factor). tol numeric tolerance value (default 1e-8) applies numerical columns. na.rm logical value. FALSE (default), missing values retained check.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/nonConstInd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Non-Constant Columns in a Data Frame — nonConstInd","text":"integer vector containing indices non-constant columns data frame. columns constant, empty vector returned.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/plot.ULDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","title":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","text":"function plots decision boundaries linear discriminant (LD) scores given ULDA model. binary classification problem, density plot created. Otherwise, scatter plot decision boundaries generated.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/plot.ULDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","text":"","code":"# S3 method for class 'ULDA' plot(x, datX, response, ...)"},{"path":"http://iamwangsiyu.com/folda/reference/plot.ULDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","text":"x fitted ULDA model object. datX data frame containing predictor variables. response factor representing response variable (training labels) corresponding datX. ... Additional arguments.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/plot.ULDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","text":"ggplot2 plot object, either density plot scatter plot decision boundaries.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/plot.ULDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Decision Boundaries and Linear Discriminant Scores — plot.ULDA","text":"","code":"fit <- folda(datX = iris[, -5], response = iris[, 5], subsetMethod = \"all\") plot(fit, iris[, -5], iris[, 5])"},{"path":"http://iamwangsiyu.com/folda/reference/predict.ULDA.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Method for ULDA Model — predict.ULDA","title":"Predict Method for ULDA Model — predict.ULDA","text":"function predicts class labels class probabilities new data using fitted ULDA model. prediction can return either likely class (\"response\") posterior probabilities class (\"prob\").","code":""},{"path":"http://iamwangsiyu.com/folda/reference/predict.ULDA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Method for ULDA Model — predict.ULDA","text":"","code":"# S3 method for class 'ULDA' predict(object, newdata, type = c(\"response\", \"prob\"), ...)"},{"path":"http://iamwangsiyu.com/folda/reference/predict.ULDA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Method for ULDA Model — predict.ULDA","text":"object fitted ULDA model object. newdata data frame containing new predictor variables predictions made. type character string specifying type prediction return. \"response\" returns predicted class labels, \"prob\" returns posterior probabilities class. Default \"response\". ... Additional arguments.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/predict.ULDA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Method for ULDA Model — predict.ULDA","text":"type = \"response\", function returns vector predicted class labels. type = \"prob\", returns matrix posterior probabilities, row corresponds sample column class.","code":""},{"path":"http://iamwangsiyu.com/folda/reference/predict.ULDA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Method for ULDA Model — predict.ULDA","text":"","code":"fit <- folda(datX = iris[, -5], response = iris[, 5], subsetMethod = \"all\")  # Predict class labels predictions <- predict(fit, iris, type = \"response\")  # Predict class probabilities prob_predictions <- predict(fit, iris, type = \"prob\")"},{"path":"http://iamwangsiyu.com/folda/news/index.html","id":"folda-010","dir":"Changelog","previous_headings":"","what":"folda 0.1.0","title":"folda 0.1.0","text":"Initial CRAN submission.","code":""}]
